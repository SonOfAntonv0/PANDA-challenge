{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Description\nThis kernel performs inference for [PANDA concat tile pooling starter](https://www.kaggle.com/iafoss/panda-concat-fast-ai-starter) kernel with use of multiple models and 8 fold TTA. Check it for more training details. The image preprocessing pipline is provided [here](https://www.kaggle.com/iafoss/panda-16x128x128-tiles)."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import cv2\nfrom tqdm import tqdm_notebook as tqdm\nimport fastai\nfrom fastai.vision import *\nimport os\nimport torch\nfrom torchvision.transforms import Compose\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nfrom mish_activation import *\nimport warnings\nimport glob\nwarnings.filterwarnings(\"ignore\")\nimport skimage.io\nimport numpy as np\nimport pandas as pd\nfrom efficientnet_pytorch import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA = '../input/prostate-cancer-grade-assessment/test_images'\nTEST = '../input/prostate-cancer-grade-assessment/test.csv'\nSAMPLE = '../input/prostate-cancer-grade-assessment/sample_submission.csv'\nMODELS=['../input/efficientnetb0medianv6/bestmodel_0 (4).pth',]\nMODELS_EF=['../input/efficientnetb0medianv14/bestmodel_5.pth']\nwpath = '../input/efficientnetb0-pretrained/efficientnet-b0-355c32eb.pth'\nsz = 256\nbs = 2\nN = 25\nnworkers = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transforms = Compose([\n     transforms.ToPILImage(),\n     transforms.RandomRotation(degrees=(-90, 90)),\n     transforms.RandomAffine(0),\n     transforms.ToTensor(),\n    ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1,stride=(2,2)),\n            nn.BatchNorm2d(mid_channels),\n            Mish(),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1,stride=(2,2)),\n            nn.BatchNorm2d(out_channels),\n            Mish()\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n\nclass Down(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\n\nclass Up(nn.Module):\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n\n        # if bilinear, use the normal convolutions to reduce the number of channels\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        # input is CHW\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n\n        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n                        diffY // 2, diffY - diffY // 2])\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass Head(nn.Module):\n    def __init__(self,n_classes,in_features):\n        super(Head,self).__init__()\n        self.head=nn.Sequential(AdaptiveConcatPool2d(),Flatten(),nn.Linear(in_features,n_classes),)\n    def forward(self,x):\n        return self.head(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Resnet34 encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.m=models.resnet34()\n        nc=list(self.m.children())[-1].in_features\n        self.enc=nn.Sequential(*list(self.m.children())[:-1])\n        self.head1=Head(in_features=2*nc,n_classes=n_classes)\n    def print(self,x):\n        print(x[0].size())\n        fig,ax=py.subplots(4,3)\n        j=0\n        for ax1 in ax:\n            for ax2 in ax1:\n                print(x[j,0,:,:].detach().numpy().size())\n                ax2.imshow(x[j,0,:,:].detach().numpy())\n                j+=1\n    \n    def forward(self, *x):\n        shape=x[0].shape\n        n_tiles=len(x)\n        x=torch.stack(x,1).view(-1,shape[1],shape[2],shape[3])\n        x1 = self.enc(x)\n        shape1=x1.size()\n        x1=x1.view(-1,shape1[1],n_tiles*shape1[2],shape1[2])\n        img = self.head1(x1)\n        shape1=img.size()\n        return img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EfficientNet B0 encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ENet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(ENet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.m=EfficientNet.from_pretrained(model_name = 'efficientnet-b0',num_classes=n_classes)\n        nc=list(self.m.children())[-2].in_features\n        self.head1=Head(in_features=2*nc,n_classes=n_classes)\n    def print(self,x):\n        print(x[0].size())\n        fig,ax=py.subplots(4,3)\n        j=0\n        for ax1 in ax:\n            for ax2 in ax1:\n                print(x[j,0,:,:].detach().numpy().size())\n                ax2.imshow(x[j,0,:,:].detach().numpy())\n                j+=1\n    \n    def forward(self, *x):\n        shape=x[0].shape\n        n_tiles=len(x)\n        x=torch.stack(x,1).view(-1,shape[1],shape[2],shape[3])\n        x1 = self.m.extract_features(x)\n        shape1=x1.size()\n        x1=x1.view(-1,shape1[1],n_tiles*shape1[2],shape1[2])#shape1[2]\n        img = self.head1(x1)\n        shape1=img.size()\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nif not os.path.exists('/root/.cache/torch/checkpoints/'):\n        os.makedirs('/root/.cache/torch/checkpoints/')\n!cp /kaggle/input/efficientnetb0-pretrained/efficientnet-b0-355c32eb.pth /root/.cache/torch/checkpoints/\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_ef = []\nfor path in MODELS_EF:\n    state_dict = torch.load(path,map_location=torch.device('cpu'))\n    model = ENet(3,6)\n    model.load_state_dict(state_dict)\n    model.float()\n    model.eval()\n    model.cuda()\n    models_ef.append(model)\n\ndel state_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tile(img):\n    shape = img.shape\n    pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],\n                 constant_values=255)\n    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n    if len(img) < N:\n        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n    img = img[idxs]\n    return img\n\nmean = torch.tensor([1.0-0.90949707, 1.0-0.8188697, 1.0-0.87795304])\nstd = torch.tensor([0.36357649, 0.49984502, 0.40477625])\n\nclass PandaDataset(Dataset):\n    def __init__(self, path, test, transform=None):\n        self.path = path\n        self.names = list(pd.read_csv(test).image_id)\n        self.transform = data_transforms\n    def __len__(self):\n        return len(self.names)\n\n    def __getitem__(self, idx):\n        name = self.names[idx]\n        img = skimage.io.MultiImage(os.path.join(DATA,name+'.tiff'))[1]\n        tiles = torch.Tensor(1.0 - tile(img)/255.0)\n        tiles=tiles.permute(0,3,1,2)\n        trans_img = []\n        for i in tiles:\n            i = self.transform(i)\n            i = (i - mean[...,None,None])/std[...,None,None]\n            trans_img.append(i)\n        tiles = torch.stack(trans_img)\n        return tiles, name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv(TEST)\nif os.path.exists(DATA):\n    ds = PandaDataset(DATA,TEST, transform = data_transforms,)\n    dl = DataLoader(ds, batch_size=bs, shuffle=False,num_workers=nworkers)\n    names,preds = [],[]\n\n    with torch.no_grad():\n        for x,y in tqdm(dl):\n            x = x.cuda()\n            x=x.permute(1,0,2,3,4)#size after permutation =(n_tiles,bs,C,H,W) \n            p1= [model(*x) for model in models_ef]\n            p1=torch.stack(p1,0)\n            p1=torch.sum(p1,dim=0)/len(p1)\n            p1=p1.argmax(-1).cpu()\n            names.append(y)\n            preds.append(p1)\n    \n    names = np.concatenate(names)\n    preds = torch.cat(preds).cpu().numpy()\n    sub_df = pd.DataFrame({'image_id': names, 'isup_grade': preds})\n    sub_df['isup_grade']=sub_df['isup_grade'].apply(int)\n    sub_df.to_csv('submission.csv', index=False)\n    sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df['isup_grade'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\", index=False)\nsub_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}